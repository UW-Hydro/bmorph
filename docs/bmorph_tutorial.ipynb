{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Getting your first bias corrections with bmorph\n",
    "This notebook demonstrates how to setup data for and bias correct it through **bmorph**, containing the same information as ``bmorph_tutorial.rst``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Load Data\n",
    "We will be using numpy, xarray, and pandas in this example notebook.\n",
    "Note: numpy can imported directly intsead of using magic, ``%pylab inline`` if desired. More on Built-in magic commands can be found [here](https://ipython.readthedocs.io/en/stable/interactive/magics.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import xarray as xr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will mainly deal with ``bmorph.core.workflows``, our primary organizing script, but will also use ``bmorph.core.mizuroute_utils`` to pre-process your data for bmorph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bmorph\n",
    "from bmorph.util import mizuroute_utils as mizutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a client for parallelism can help speed up the process\n",
    "of bias correction immensely, espeically if you are working with large numbers of\n",
    "watersheds. Calibrating which meteorological variable you want to condition to can take\n",
    "some time, so parralelism is recommended in especially the initial uses of ``bmorph``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you are just copying this over, the client is only set up with\n",
    "one thread and one worker to prevent accidentally overburdening any\n",
    "machine this is running on. If you actually want to use parallelism, \n",
    "make sure to change this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(threads_per_worker=1, n_workers=1) #Increase for parallel power!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you provide the gauge site names and their respective river segment identification\n",
    "numbers, or ``site``'s and ``seg``'s. This will be used throughout to ensure the data does\n",
    "not get mismatched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_to_seg = { site_0_name : site_0_seg, ...} # Input this mapping or read it from a text file before running!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is nice to be able to access the data you just filled out without much struggle, here we create\n",
    "some other useful forms of these gauge site mappings for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_to_site = {seg: site for site, seg in site_to_seg.items()}\n",
    "ref_sites = list(site_to_seg.keys())\n",
    "ref_segs = list(site_to_seg.values())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load in topographical data (topo), meterological data (met), \n",
    "uncorrected flows (raw), and reference flows (ref). Note that some\n",
    "fields have placeholder names that you should update before running.\n",
    "If some data is not accessible in a single function call, be sure to collapse\n",
    "it into a single file first before loading them. File designation calls assume\n",
    "this code is in a folder seperate from the data, but that this code's containing\n",
    "folder is at the same heirarchy as the folders containing the data. A description\n",
    "of how your project directory is expected to be set up can be found in ``data.rst``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_topo = xr.open_dataset('../topologies/basin_topology_file_name.nc').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes meteorological data may only be available for a larger region\n",
    "or watershed than anlayzing, so the following data will be described under such\n",
    "an assumption.\n",
    "    \n",
    "Here we load in some example meteorological data: daily minimum temperature (tmin), seasonal precipitation (prec),\n",
    "and daily maximum temperature (tmax). You can use similar or completely different data, just note naming should be universally updated and unused names should be deleted or commented out completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_met = xr.open_dataset('../input/tmin.nc').load()\n",
    "watershed_met['seasonal_precip'] = xr.open_dataset('../input/prec.nc')['prec'].load().rolling(time=30, min_periods=1).sum()\n",
    "watershed_met['tmax'] = xr.open_dataset('../input/tmax.nc')['tmax'].load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hydrualic response units (hru's) are the typical coordinate for meteorologic data. Later, mizuroute_utils\n",
    "will take care of mapping these hru's to seg's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_met['hru'] = (watershed_met['hru'] - 1.7e7).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last not be certainly not least, we need the flows themselves! ``bmorph`` is designed to bias \n",
    "correct simulated streamflow as modeled by [mizuroute](https://mizuroute.readthedocs.io/en/latest/). As a result, loading\n",
    "up the raw flows involves combining a number of flow netcdf files, hence the ``open_mfdataset``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_raw = xr.open_mfdataset('../input/first_route*.nc')[['IRFroutedRunoff', 'dlayRunoff', 'reachID']].load()\n",
    "watershed_raw['seg'] = watershed_raw.isel(time=0)['reachID'].astype(np.int32)\n",
    "watershed_ref = xr.open_dataset('../input/nrni_reference_flows.nc').load().rename({'outlet':'site'})[['seg', 'seg_id', 'reference_flow']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select data for the basin of analysis from the larger watershed, we \n",
    "need the topology of the larger watershed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_topo = xr.open_dataset('../topologies/watershed_topology_file_name.nc').load()\n",
    "watershed_topo = watershed_topo.where(watershed_topo['hru'] < 1.79e7, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we clean up a few naming conventions to get everything on the same page in accordance with ``data.rst``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'hru_id2' in basin_topo:\n",
    "    basin_topo['hru'] = basin_topo['hru_id2']\n",
    "if 'seg_id' in basin_topo:\n",
    "    basin_topo['seg'] = basin_topo['seg_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert ``mizuroute`` formatting to ``bmorph`` formatting\n",
    "\n",
    "``mizuroute_utils`` is our utility script that will handle converting\n",
    "Mizuroute outputs to what we need for ``bmorph``. For more information\n",
    "on what ``mizuroute_utils`` does specifically and how to change its \n",
    "parameters, check out ``data.rst``.\n",
    "\n",
    "Here we pull out coordinate data from the ovearching watershed\n",
    "for the specific basin we want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_ref = watershed_ref.sel(site=[r for r in ref_sites])\n",
    "\n",
    "for site, seg in site_to_seg.items():\n",
    "    if site in basin_ref['site']:\n",
    "        basin_ref['seg'].loc[{'site': site}] = seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pass it off to ``mizuroute_to_blendmorph``, the primary utility \n",
    "function for automating ``bmorph`` pre-procesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_met_seg = mizutil.mizuroute_to_blendmorph(\n",
    "    basin_topo, watershed_raw.copy(), basin_ref, watershed_met, \n",
    "    fill_method='r2').ffill(dim='seg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply ``bmorph`` bias correction\n",
    "\n",
    "We are almost to actually bias correcting! First we need to specify some parameters \n",
    "for correction. Returning to these parameters can help fine tune your bias \n",
    "corrections to the basin you are analyzing.\n",
    "\n",
    "In this notebook, all four variations of ``bmorph`` are demonstrated: \n",
    "IBC_U, IBC_C, SCBC_U, and SCBC_C, as described in ``bias_correction.rst``.\n",
    "\n",
    "The ``train_window`` is what we will use to train the bias correction\n",
    "model. This is the time range that is representative of the\n",
    "basin's expected behavior that ``bmorph`` should mirror.\n",
    "\n",
    "The ``bmorph_window`` is when ``bmorph`` should be applied to the series for\n",
    "bias correction.\n",
    "\n",
    "Lastly the ``reference_window`` is when the reference flows should be used to \n",
    "smooth the bias corrected flows. This is recommended to be set as equivalent to the\n",
    "``train_window``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = pd.date_range('1981-01-01', '1990-12-30')[[0, -1]]\n",
    "bmorph_window = pd.date_range('1991-01-01', '2005-12-30')[[0, -1]]\n",
    "reference_window = train_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``interval`` is the length of``bmorph``'s application intervals, \n",
    "typically a factor of years to preserve hydrologic \n",
    "relationships. Note that for ``pandas.DateOffset``, 'year' and 'years' \n",
    "are different and an 's' should always be included here for ``bmorph``\n",
    "to run properly, even for a single year.\n",
    "\n",
    "``overlap`` describes how many days the bias correction cumulative distribtuion function\n",
    "windows should overlap in total with each other. ``overlap`` is evenly distributed before\n",
    "and after this window. This is used to reduce discontinuities between application periods.\n",
    "\n",
    "``condition_var`` names the variable to use in conditioning, such as maximum\n",
    "temperature (tmax), seasonal precipitation (seasonal_precip), or daily\n",
    "minimum temperature (tmin). At this time, only one conditioning\n",
    "meteorological variable can be used per ``bmorph`` execution. In this example,\n",
    "``tmax`` and ``seasonal_precip`` have been commented out to select ``tmin`` as\n",
    "the conditioning variable. If you wish to change this, be sure to either change\n",
    "which variables are commented out or change the value of ``condition_var`` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = pd.DateOffset(years=1)\n",
    "overlap = 90\n",
    "\n",
    "#condition_var = 'tmax'\n",
    "#condition_var = 'seasonal_precip'\n",
    "condition_var = 'tmin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we name some configuration parameters for ``bmorph``'s conditional and univariate\n",
    "bias correction metods, respectively. If you have been following along with the\n",
    "rest of the naming conventions in this section so far, then there is\n",
    "nothing you need to change here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditonal_config = {\n",
    "    'train_window': train_window,\n",
    "    'bmorph_window': bmorph_window,\n",
    "    'reference_window': reference_window,\n",
    "    'bmorph_interval': interval,\n",
    "    'bmorph_overlap': overlap,\n",
    "    'condition_var': condition_var\n",
    "}\n",
    "\n",
    "univariate_config = {\n",
    "    'train_window': train_window,\n",
    "    'bmorph_window': bmorph_window,\n",
    "    'reference_window': reference_window,\n",
    "    'bmorph_interval': interval,\n",
    "    'bmorph_overlap': overlap,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You made it! Now we can actually bias correction with ``bmorph``! Depending\n",
    "on the size of your data and use of parallelism or not, the following cells\n",
    "will likely take the longest to run, so make certain everything else looks\n",
    "good to you before running it.\n",
    "\n",
    "First off we run the Independent Bias Corrections, which is completely contained\n",
    "in the cell below. If you are interested in ``bmorph``'s spatial consitency and conditioing\n",
    "bias corrections, this cell is not it. However, it can be useful to run at least once\n",
    "so you have a baseline method to compare to as you fine tune variables.\n",
    "\n",
    "Here we run through each of the gauge sites and correct them \n",
    "individually. Since independent bias correction can only be performed\n",
    "at locations with reference data, corrections are only performed at\n",
    "the gauge sites here. If you have not changed any naming conventions\n",
    "so far, then there is nothing that you need to alter here, it has all already\n",
    "been extracted above for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_u_flows = {}\n",
    "ibc_u_mults = {}\n",
    "ibc_c_flows = {}\n",
    "ibc_c_mults = {}\n",
    "\n",
    "raw_flows = {}\n",
    "ref_flows = {}\n",
    "\n",
    "for site, seg in site_to_seg.items():\n",
    "    raw_ts = basin_met_seg.sel(seg=seg)['IRFroutedRunoff'].to_series()\n",
    "    train_ts = basin_met_seg.sel(seg=seg)['IRFroutedRunoff'].to_series()\n",
    "    obs_ts = basin_met_seg.sel(seg=seg)['up_ref_flow'].to_series()\n",
    "    cond_var = basin_met_seg.sel(seg=seg)[f'up_{condition_var}'].to_series()\n",
    "    ref_flows[site] = obs_ts\n",
    "    raw_flows[site] = raw_ts\n",
    "\n",
    "    ## IBC_U (Independent Bias Correction: Univariate)\n",
    "    ibc_u_flows[site], ibc_u_mults[site] = bmorph.workflows.apply_interval_bmorph(\n",
    "        raw_ts, train_ts, obs_ts, train_window, bmorph_window, reference_window, interval, overlap)\n",
    "\n",
    "    ## IBC_C (Independent Bias Correction: Conditioned)\n",
    "    ibc_c_flows[site], ibc_c_mults[site] = bmorph.workflows.apply_interval_bmorph(\n",
    "        raw_ts, train_ts, obs_ts, train_window, bmorph_window, reference_window, interval, overlap,\n",
    "        raw_y=cond_var, train_y=cond_var, obs_y=cond_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you specify where ``mizuroute`` is installed on your system\n",
    "and set up some variables to store total flows.\n",
    "\n",
    "``output_prefix`` will be used to write and load files according to the\n",
    "basin's name, make certain to update this with the actual name of\n",
    "the basin you are analyzing so you can track where different files\n",
    "are writen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mizuroute_exe = # mizuroute designation\n",
    "\n",
    "unconditioned_totals = {}\n",
    "conditioned_totals = {}\n",
    "output_prefix = # basin name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use ``run_parallel_scbc`` to do the rest! This may take a while ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconditioned_totals = bmorph.workflows.run_parallel_scbc(basin_met_seg, client, output_prefix, mizuroute_exe, univariate_config)\n",
    "conditioned_totals = bmorph.workflows.run_parallel_scbc(basin_met_seg, client, output_prefix, mizuroute_exe, conditonal_config)\n",
    "\n",
    "# Here we select out our rerouted gauge site modeled flows.\n",
    "for site, seg in site_to_seg.items():\n",
    "    unconditioned_totals[site] = unconditioned_totals['IRFroutedRunoff'].sel(seg=seg)\n",
    "    conditioned_totals[site] = conditioned_totals['IRFroutedRunoff'].sel(seg=seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we combine all the data into a singular xarray.Dataset, putting a nice little bow\n",
    "on your basin's analysis. If you did not run all parts of bmoprh, make certain to comment\n",
    "out those lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scbc_c = bmorph.workflows.bmorph_to_dataarray(conditioned_totals, 'scbc_c')\n",
    "basin_analysis = xr.Dataset(coords={'site': list(site_to_seg.keys()), 'time': scbc_c['time']})\n",
    "basin_analysis['scbc_c'] = scbc_c\n",
    "basin_analysis['scbc_u'] = bmorph.workflows.bmorph_to_dataarray(unconditioned_totas, 'scbc_u')\n",
    "basin_analysis['ibc_u'] = bmorph.workflows.bmorph_to_dataarray(ibc_u_flows, 'ibc_u')\n",
    "basin_analysis['ibc_c'] = bmorph.workflows.bmorph_to_dataarray(ibc_c_flows, 'ibc_c')\n",
    "basin_analysis['raw'] = bmorph.workflows.bmorph_to_dataarray(raw_flows, 'raw')\n",
    "basin_analysis['ref'] = bmorph.workflows.bmorph_to_dataarray(ref_flows, 'ref')\n",
    "basin_analysis.to_netcdf(f'../output/{output_prefix.lower()}_data_processed.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
