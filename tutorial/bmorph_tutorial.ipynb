{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Getting your first bias corrections with bmorph\n",
    "This notebook demonstrates how to setup data for and bias correct it through **bmorph**, it contains the same information as the [tutorial](bmorph_tutorial.rst) page.\n",
    "In this notebook, we will demonstrate how to perform four variations of bias correction.\n",
    "\n",
    "* Independent Bias Correction: Univariate (IBC_U) : IBC_U is the traditional bias correction method. This method can only be performed at sites with reference data.\n",
    "* Independent Bias Correction: Conditioned (IBC_C) : IBC_C allows for correcting for specific biases that are process-dependent. This method can only be performed at sites with reference data.\n",
    "* Spatially Consistent Bias Correction: Univariate (SCBC_U): SCBC_U corrects local flows at each river reach in the network, and then reroutes them to aggregate, producing bias corrected flows everywhere.\n",
    "* Spatially Consistent Bias Correction: Conditioned (SCBC_C): SCBC_C also corrects the local flows like SCBC_U, but allows for conditioning on dependent processes.\n",
    "\n",
    "## Import Packages and Load Data\n",
    "\n",
    "We start by importing the necessary packages for the notebook.\n",
    "This notebook mainly shows how to use ``bmorph.core.workflows`` and ``bmorph.core.mizuroute_utils`` to bias correct streamflow data in the Yakima river basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "# Set a bigger default plot size\n",
    "mpl.rcParams['figure.figsize'] = (10, 8)\n",
    "\n",
    "# Import bmorph, and mizuroute utilities\n",
    "import bmorph\n",
    "from bmorph.util import mizuroute_utils as mizutil\n",
    "from bmorph.evaluation import plotting as bplot\n",
    "\n",
    "# Set the environment directory, this is a workaround for portability\n",
    "envdir = os.path.dirname(sys.executable)\n",
    "\n",
    "# Import pyproj and set the data directory, this is a workaround for portability\n",
    "import pyproj\n",
    "pyproj.datadir.set_data_dir(f'{envdir}/../share/proj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting mizuroute and sample data\n",
    "\n",
    "The following code cell has three commands preceded by `!`, which indicates that they are shell command. The first command will install mizuroute into the environment. The second two will download the sample data and unpackage it. The sample data can be viewed as a HydroShare resource [here](https://www.hydroshare.org/resource/fd2a347d34f145b4bfa8b6bff39c782b/). This cell may take a few moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda install -c conda-forge mizuroute -y\n",
    "#! wget https://www.hydroshare.org/resource/fd2a347d34f145b4bfa8b6bff39c782b/data/contents/bmorph_testdata.tar.gz\n",
    "#! tar xvf bmorph_testdata.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data study site: the Yakima river basin\n",
    "\n",
    "Before getting into how to run bmorph, let's look at what is in the sample data. You will note that we now have a `yakima_workflow` directory. This contains all of the data that you need to run the tutorial. There are a few subdirectories:\n",
    "\n",
    " * `gis_data`: contains shapefiles, this is mainly used for plotting, not for analysis\n",
    " * `input`: this is the input meteorologic data, simulated streamflow to be corrected, and the reference flow dataset\n",
    " * `mizuroute_configs`: this is an empty directory that will automatically be populated with mizuroute configuration files during the bias correction process\n",
    " * `output`: this is an empty directory that will be where the bias corrected flows will be written out to\n",
    " * `topologies`: this contains the stream network topologies that will be used for routing flows via mizuroute\n",
    " \n",
    "The Yakima river basin is a tributary of the Columbia river basin in the Pacific northwestern United States. It's western half is situated in the Cascade mountains and receives seasonal snowpack. The eastern half is lower elevation and is semi-arid. Let's load up the shapefiles for the sub-basins and stream network and plot it. In this discretization we have 285 sub-basins (HRU) and 143 stream segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yakima_hru = gpd.read_file('./yakima_workflow/gis_data/yakima_hru.shp').to_crs(\"EPSG:4326\")\n",
    "yakima_seg = gpd.read_file('./yakima_workflow/gis_data/yakima_seg.shp').to_crs(\"EPSG:4326\")\n",
    "\n",
    "ax = yakima_hru.plot(color='grey')\n",
    "yakima_seg.plot(ax=ax)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up some metadata\n",
    "\n",
    "Next you provide the gauge site names and their respective river segment identification\n",
    "numbers, or ``site``'s and ``seg``'s. This will be used throughout to ensure the data does\n",
    "not get mismatched. \n",
    "\n",
    "bmorph uses the convention:\n",
    "`site_to_seg = { site_0_name : site_0_seg, ..., site_n_name, site_n_seg}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_to_seg = {'KEE' : 4175, 'KAC' : 4171, 'EASW': 4170, \n",
    "               'CLE' : 4164, 'YUMW': 4162, 'BUM' : 5231,\n",
    "               'AMRW': 5228,  'CLFW': 5224,  'RIM' : 5240,\n",
    "               'NACW': 5222, 'UMTW': 4139,  'AUGW': 594,  \n",
    "               'PARW': 588,   'YGVW': 584,   'KIOW': 581}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is convenient to be able to access this data in different orders we also set up \n",
    "some other useful forms of these gauge site mappings for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_to_site = {seg: site for site, seg in site_to_seg.items()}\n",
    "ref_sites = list(site_to_seg.keys())\n",
    "ref_segs = list(site_to_seg.values())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load in stream network topology (topo), meteorlogical data (met), \n",
    "uncorrected flows (raw), and reference flows (ref). \n",
    "A description of how your project directory is expected to be set up can be found in [the documentation](https://bmorph.readthedocs.io/en/develop/data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yakima_topo = xr.open_dataset('yakima_workflow/topologies/yakima_huc12_topology.nc').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load in some example meteorological data that will be used for conditional bias correction: daily minimum temperature (`tmin`), seasonal precipitation (`prec`),\n",
    "and daily maximum temperature (`tmax`). In principle, any type of data can be used for conditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yakima_met = xr.open_dataset('yakima_workflow/input/yakima_met.nc').load()\n",
    "yakima_met['hru'] = (yakima_met['hru'] - 1.7e7).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we load the simulated flows and reference flows. \n",
    "bmorph is designed to bias correct streamflow simulated with [mizuroute](https://mizuroute.readthedocs.io/en/latest/). \n",
    "We denote the simulated flows as the \"raw\" flows when they are uncorrected, and the flows that will be used to correct the raw flows as the reference flows. \n",
    "In our case the reference flows are estimated no-reservoir-no-irrigation (NRNI) flows taken from the [River Management Joint Operating Committee (RMJOC)](https://www.bpa.gov/p/Generation/Hydro/Documents/RMJOC-II_Part_II.PDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw flows\n",
    "yakima_raw = xr.open_dataset('yakima_workflow/input/yakima_raw_flows.nc')[['IRFroutedRunoff', 'dlayRunoff', 'reachID']].load()\n",
    "# Update some metadata\n",
    "yakima_raw['seg'] = yakima_raw.isel(time=0)['reachID'].astype(np.int32)\n",
    "\n",
    "# Reference flows - this contains sites from the entire Columbia river basin\n",
    "yakima_ref = xr.open_dataset('yakima_workflow/input/nrni_reference_flows.nc').rename({'outlet':'site'})[['seg', 'seg_id', 'reference_flow']]\n",
    "# Pull out only the sites in the Yakima basin\n",
    "yakima_ref = yakima_ref.sel(site=ref_sites).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from ``mizuroute`` output to ``bmorph`` format\n",
    "\n",
    "``mizuroute_utils`` is our utility module that will handle converting mizuroute outputs to the format that we need for ``bmorph``. \n",
    "We will use the `mizutil.to_bmorph` function to merge together all of the data we previously loaded, and calculate some extra pieces of information to perform spatially consistent bias corrections (SCBC).\n",
    "For more information about how we perform SCBC see [the SCBC page in the documentation](https://bmorph.readthedocs.io/en/develop/bias_correction.html#spatial-consistency-reference-site-selection-cdf-blend-factor).\n",
    "Now we pass our data in to ``to_bmorph``, the primary utility function for automating ``bmorph`` pre-procesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yakima_met_seg = mizutil.to_bmorph(yakima_topo, yakima_raw, yakima_ref, yakima_met,  fill_method='r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up ``bmorph`` configuration and parameters\n",
    "\n",
    "Before applying bias correction we need to specify some parameters and configuration\n",
    "for correction. Returning to these steps can help fine tune your bias \n",
    "corrections to the basin you are analyzing.\n",
    "\n",
    "The ``train_window`` is what we will use to train the bias correction\n",
    "model. This is the time range that is representative of the\n",
    "basin's expected behavior that ``bmorph`` should mirror.\n",
    "\n",
    "The ``bmorph_window`` is when ``bmorph`` should be applied to the series for\n",
    "bias correction.\n",
    "\n",
    "Lastly the ``reference_window`` is when the reference flows should be used to \n",
    "smooth the bias corrected flows. This is recommended to be set as equivalent to the\n",
    "``train_window``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = pd.date_range('1981-01-01', '1990-12-30')[[0, -1]]\n",
    "bmorph_window = pd.date_range('1991-01-01', '2005-12-30')[[0, -1]]\n",
    "reference_window = train_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``interval`` is the length of ``bmorph``'s application intervals, \n",
    "typically a factor of years to preserve hydrologic \n",
    "relationships. Note that for ``pandas.DateOffset``, 'year' and 'years' \n",
    "are different and an 's' should always be included here for ``bmorph``\n",
    "to run properly, even for a single year.\n",
    "\n",
    "``overlap`` describes how many days the bias correction cumulative distribution function\n",
    "windows should overlap in total with each other. ``overlap`` is evenly distributed before\n",
    "and after this window. This is used to reduce discontinuities between application periods.\n",
    "\n",
    "``condition_var`` names the variable to use in conditioning, such as maximum\n",
    "temperature (tmax), seasonal precipitation (seasonal_precip), or daily\n",
    "minimum temperature (tmin). At this time, only one conditioning\n",
    "meteorological variable can be used per ``bmorph`` execution. In this example,\n",
    "``tmax`` and ``seasonal_precip`` have been commented out to select ``tmin`` as\n",
    "the conditioning variable. If you wish to change this, be sure to either change\n",
    "which variables are commented out or change the value of ``condition_var`` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = pd.DateOffset(years=1)\n",
    "overlap = 90\n",
    "\n",
    "# Select from the various available meteorologic fields for conditioning\n",
    "#condition_var = 'tmax'\n",
    "#condition_var = 'seasonal_precip'\n",
    "condition_var = 'tmin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we name some configuration parameters for ``bmorph``'s conditional and univariate\n",
    "bias correction methods, respectively. \n",
    "\n",
    "``output_prefix`` will be used to write and load files according to the\n",
    "basin's name, make certain to update this with the actual name of\n",
    "the basin you are analyzing so you can track where different files\n",
    "are written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditonal_config = {\n",
    "    'data_path':  './yakima_workflow',\n",
    "    'output_prefix': \"yakima\",\n",
    "    'train_window': train_window,\n",
    "    'bmorph_window': bmorph_window,\n",
    "    'reference_window': reference_window,\n",
    "    'bmorph_interval': interval,\n",
    "    'bmorph_overlap': overlap,\n",
    "    'condition_var': condition_var\n",
    "}\n",
    "\n",
    "univariate_config = {\n",
    "    'data_path':  './yakima_workflow',\n",
    "    'output_prefix': \"yakima\",\n",
    "    'train_window': train_window,\n",
    "    'bmorph_window': bmorph_window,\n",
    "    'reference_window': reference_window,\n",
    "    'bmorph_interval': interval,\n",
    "    'bmorph_overlap': overlap,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You made it! Now we can actually bias correction with ``bmorph``! \n",
    "\n",
    "First off we run the Independent Bias Corrections, which are completely contained\n",
    "in the cell below. \n",
    "\n",
    "Here we run through each of the gauge sites and correct them \n",
    "individually. Since independent bias correction can only be performed\n",
    "at locations with reference data, corrections are only performed at\n",
    "the gauge sites here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_u_flows = {}\n",
    "ibc_u_mults = {}\n",
    "ibc_c_flows = {}\n",
    "ibc_c_mults = {}\n",
    "\n",
    "raw_flows = {}\n",
    "ref_flows = {}\n",
    "for site, seg in tqdm(site_to_seg.items()):\n",
    "    raw_ts =   yakima_met_seg.sel(seg=seg)['IRFroutedRunoff'].to_series()\n",
    "    train_ts = yakima_met_seg.sel(seg=seg)['IRFroutedRunoff'].to_series()\n",
    "    obs_ts =   yakima_met_seg.sel(seg=seg)['up_ref_flow'].to_series()\n",
    "    cond_var = yakima_met_seg.sel(seg=seg)[f'up_{condition_var}'].to_series()\n",
    "    ref_flows[site] = obs_ts\n",
    "    raw_flows[site] = raw_ts\n",
    "\n",
    "    ## IBC_U (Independent Bias Correction: Univariate)\n",
    "    ibc_u_flows[site], ibc_u_mults[site] = bmorph.workflows.apply_interval_bmorph(\n",
    "        raw_ts, train_ts, obs_ts, train_window, bmorph_window, reference_window, interval, overlap)\n",
    "\n",
    "    ## IBC_C (Independent Bias Correction: Conditioned)\n",
    "    ibc_c_flows[site], ibc_c_mults[site] = bmorph.workflows.apply_interval_bmorph(\n",
    "        raw_ts, train_ts, obs_ts, train_window, bmorph_window, reference_window, interval, overlap,\n",
    "        raw_y=cond_var, train_y=cond_var, obs_y=cond_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatially consistent bias correction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specify where the ``mizuroute`` executable is installed on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'envdir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fd5c28e0fe9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmizuroute_exe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{envdir}/route_runoff.exe'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'envdir' is not defined"
     ]
    }
   ],
   "source": [
    "mizuroute_exe = f'{envdir}/route_runoff.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use ``run_parallel_scbc`` to do the rest. \n",
    "The next two cells may each take up to 3 minutes to run.\n",
    "In the first cell we will run the spatially-consistent bias correction without any conditioning. \n",
    "The second cell will run the spatially-consistent bias correction with conditioning.\n",
    "This produced bias corrected flows at all 143 stream segments in the Yakima river basin.\n",
    "Finally, we select out the corrected streamflows for both cases (with and without conditioning) to only contain the gauged sites.\n",
    "Selecting out only the gauged locations allows us to compare the spatially-consistent methods with the independent bias corrections.\n",
    "Finally we combine all the data into a single xarray `Dataset` to make analysis easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCBC without conditioning\n",
    "unconditioned_seg_totals = bmorph.workflows.run_parallel_scbc(yakima_met_seg, mizuroute_exe, univariate_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCBC with conditioning\n",
    "conditioned_seg_totals = bmorph.workflows.run_parallel_scbc(yakima_met_seg, mizuroute_exe, conditonal_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we select out our rerouted gauge site modeled flows.\n",
    "unconditioned_site_totals = {}\n",
    "conditioned_site_totals = {}\n",
    "for site, seg in tqdm(site_to_seg.items()):\n",
    "    unconditioned_site_totals[site] = unconditioned_seg_totals['IRFroutedRunoff'].sel(seg=seg).to_series()\n",
    "    conditioned_site_totals[site] = conditioned_seg_totals['IRFroutedRunoff'].sel(seg=seg).to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge everything together\n",
    "yakima_analysis = xr.Dataset(coords={'site': list(site_to_seg.keys()), 'time': scbc_c['time']})\n",
    "yakima_analysis['scbc_c'] = bmorph.workflows.bmorph_to_dataarray(conditioned_site_totals, 'scbc_c')\n",
    "yakima_analysis['scbc_u'] = bmorph.workflows.bmorph_to_dataarray(unconditioned_site_totals, 'scbc_u')\n",
    "yakima_analysis['ibc_u'] = bmorph.workflows.bmorph_to_dataarray(ibc_u_flows, 'ibc_u')\n",
    "yakima_analysis['ibc_c'] = bmorph.workflows.bmorph_to_dataarray(ibc_c_flows, 'ibc_c')\n",
    "yakima_analysis['raw'] = bmorph.workflows.bmorph_to_dataarray(raw_flows, 'raw')\n",
    "yakima_analysis['ref'] = bmorph.workflows.bmorph_to_dataarray(ref_flows, 'ref')\n",
    "yakima_analysis.to_netcdf(f'./yakima_workflow/output/{univariate_config[\"output_prefix\"]}_data_processed.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's take a look at our results\n",
    "\n",
    "If you look closely, the following plots are the same ones included in [Plotting](evaluation.rst/Plotting)! Because the plotting functions expect the variable `seg`, we will need to conflate `site` and `seg` for them to properly run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yakima_ds = xr.open_dataset(f'yakima_workflow/output/{univariate_config[\"output_prefix\"]}_data_processed.nc')\n",
    "yakima_ds = yakima_ds.rename({'site':'seg'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a few sites and colors to plot for consistency. To simplify our plots, we will only focus on `scbc_c` in the dataset we just created. The methods do allow for multiple methods to be compared at once however, so we will still need to store the singular `scbc_c` in a list.\n",
    "\n",
    "Feel free to mess around with the parameters of any of these plots. You can plot more sites if desired, or more methods, just make certain arguments properly line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_sites = ['KIOW','YUMW','BUM']\n",
    "select_sites_2 = ['KIOW','YUMW','BUM','KEE']\n",
    "bcs = ['scbc_c', 'scbc_u', 'ibc_c', 'ibc_u']\n",
    "colors = ['grey', 'black', 'red', 'orange', 'purple', 'blue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.compare_correction_scatter(\n",
    "    flow_dataset= yakima_ds, \n",
    "    plot_sites = select_sites,\n",
    "    raw_var = 'raw', \n",
    "    ref_var = 'ref', \n",
    "    bc_vars = bcs, \n",
    "    bc_names = [bc.upper() for bc in bcs],\n",
    "    plot_colors = list(colors[2:]),\n",
    "    pos_cone_guide = True,\n",
    "    neg_cone_guide = True,\n",
    "    symmetry = False,\n",
    "    title = '',\n",
    "    fontsize_legend = 120,\n",
    "    alpha = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bplot.plot_reduced_flows(\n",
    "    flow_dataset= yakima_ds, \n",
    "    plot_sites = select_sites_2, \n",
    "    interval = 'month',\n",
    "    raw_var = 'raw', raw_name = \"Uncorrected\",\n",
    "    ref_var = 'ref', ref_name = \"Reference\",\n",
    "    bc_vars = bcs, bc_names = [bc.upper() for bc in bcs],\n",
    "    plot_colors = colors\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilitiy Distribtutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bplot.compare_mean_grouped_CPD(\n",
    "    flow_dataset= yakima_ds, \n",
    "    plot_sites = select_sites,\n",
    "    grouper_func = plotting.calc_water_year, \n",
    "    figsize = (60,40),\n",
    "    raw_var = 'raw', raw_name = 'Uncorrected',\n",
    "    ref_var = 'ref', ref_name = 'Reference',\n",
    "    bc_vars = bcs, bc_names = [bc.upper() for bc in bcs],\n",
    "    plot_colors = colors,\n",
    "    linestyles = 2 * ['-','-','-'],\n",
    "    markers = ['o', 'X', 'o', 'o', 'o', 'o'],\n",
    "    fontsize_legend = 90,\n",
    "    legend_bbox_to_anchor = (1.9,1.0)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box & Whisker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bplot.kl_divergence_annual_compare(\n",
    "    flow_dataset= yakima_ds, \n",
    "    sites = select_sites,\n",
    "    fontsize_legend = 60, title = '',\n",
    "    raw_var = 'raw', raw_name = 'Uncorrected',\n",
    "    ref_var = 'ref', ref_name = 'Reference',\n",
    "    bc_vars = bcs, bc_names = [bc.upper() for bc in bcs],\n",
    "    plot_colors = ['grey','red', 'orange', 'purple', 'blue']\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmorph",
   "language": "python",
   "name": "bmorph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
