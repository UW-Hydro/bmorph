{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Getting your first bias corrections with bmorph\n",
    "This notebook demonstrates how to setup data for and bias correct it through **bmorph**, it contains the same information as the [tutorial](bmorph_tutorial.rst) page.\n",
    "\n",
    "## Import Packages and Load Data\n",
    "\n",
    "We start by importing the necessary packages for the notebook.\n",
    "This notebook mainly shows how to use ``bmorph.core.workflows`` and ``bmorph.core.mizuroute_utils`` to bias correct streamflow data in the Yakima river basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "# Set a bigger default plot size\n",
    "mpl.rcParams['figure.figsize'] = (10, 8)\n",
    "\n",
    "# Import bmorph, and mizuroute utilities\n",
    "import bmorph\n",
    "from bmorph.util import mizuroute_utils as mizutil\n",
    "\n",
    "# Set the environment directory, this is a workaround for portability\n",
    "envdir = os.path.dirname(sys.executable)\n",
    "\n",
    "# Import pyproj and set the data directory, this is a workaround for portability\n",
    "import pyproj\n",
    "pyproj.datadir.set_data_dir(f'{envdir}/../share/proj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick note on parallelism\n",
    "bmorph supports bias correcting in parallel through `dask`. Here we set up a simple `Client` object which manages how computations are distributed. For this tutorial we will only use a single process, but increasing the `n_workers` will result in using more processors, when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(threads_per_worker=1, n_workers=1) #Increase for parallel power!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting mizuroute and sample data\n",
    "\n",
    "The following code cell has three commands preceeded by `!`, which indicates that they are shell command. The first command will install mizuroute into the environment. The second two will download the sample data and unpackage it. The sample data can be viewed as a HydroShare resource [here](https://www.hydroshare.org/resource/fd2a347d34f145b4bfa8b6bff39c782b/). This cell may take a few moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda install -c conda-forge mizuroute -y\n",
    "! wget https://www.hydroshare.org/resource/fd2a347d34f145b4bfa8b6bff39c782b/data/contents/bmorph_testdata.tar.gz\n",
    "! tar xvf bmorph_testdata.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data study site: the Yakima river basin\n",
    "\n",
    "Before getting into how to run bmorph, let's look at what is in the sample data. You will note that we now have a `yakima_workflow` directory. This contains all of the data that you need to run the tutorial. There are a few subdirectories:\n",
    "\n",
    " * `gis_data`: contains shapefiles, this is mainly used for plotting, not for analysis\n",
    " * `input`: this is the input meteorologic data, simulated streamflow to be corrected, and the reference flow dataset\n",
    " * `mizuroute_configs`: this is an empty directory that will automatically be populated with mizuroute configuration files during the bias correction process\n",
    " * `output`: this is an empty directory that will be where the bias corrected flows will be written out to\n",
    " * `topologies`: this contains the stream network topologies that will be used for routing flows via mizuroute\n",
    " \n",
    "The Yakima river basin is a tributary of the Columbia river basin in the Pacific northwestern United States. It's western half is situated in the Cascade moutains and recieves seasonal snowpack. The eastern half is lower elevation and is semi-arid. Let's load up the shapefiles for the sub-basins and stream network and plot it. In this discretization we have 285 sub-basins (HRU) and 143 stream segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yakima_hru = gpd.read_file('./yakima_workflow/gis_data/yakima_hru.shp').to_crs(\"EPSG:4326\")\n",
    "yakima_seg = gpd.read_file('./yakima_workflow/gis_data/yakima_seg.shp').to_crs(\"EPSG:4326\")\n",
    "\n",
    "ax = yakima_hru.plot(color='grey')\n",
    "yakima_seg.plot(ax=ax)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up some metadata\n",
    "\n",
    "Next you provide the gauge site names and their respective river segment identification\n",
    "numbers, or ``site``'s and ``seg``'s. This will be used throughout to ensure the data does\n",
    "not get mismatched. \n",
    "\n",
    "bmorph uses the convention:\n",
    "`site_to_seg = { site_0_name : site_0_seg, ..., site_n_name, site_n_seg}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_to_seg = {'KEE' : 4175, 'KAC' : 4171, 'EASW': 4170, \n",
    "               'CLE' : 4164, 'YUMW': 4162, 'BUM' : 5231,\n",
    "               'AMRW': 5228,  'CLFW': 5224,  'RIM' : 5240,\n",
    "               'NACW': 5222, 'UMTW': 4139,  'AUGW': 594,  \n",
    "               'PARW': 588,   'YGVW': 584,   'KIOW': 581}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is nice to be able to access the data you just filled out without much struggle, here we create\n",
    "some other useful forms of these gauge site mappings for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_to_site = {seg: site for site, seg in site_to_seg.items()}\n",
    "ref_sites = list(site_to_seg.keys())\n",
    "ref_segs = list(site_to_seg.values())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load in stream network topology (topo), meterological data (met), \n",
    "uncorrected flows (raw), and reference flows (ref). \n",
    "A description of how your project directory is expected to be set up can be found in [the documentation](https://bmorph.readthedocs.io/en/develop/data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_topo = xr.open_dataset('yakima_workflow/topologies/yakima_huc12_topology.nc').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load in some example meteorological data that will be used for conditional bias correction: daily minimum temperature (`tmin`), seasonal precipitation (`prec`),\n",
    "and daily maximum temperature (`tmax`). In principle, any type of data can be used for conditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_met = xr.open_dataset('yakima_workflow/input/yakima_met.nc').load()\n",
    "watershed_met['hru'] = (watershed_met['hru'] - 1.7e7).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we load the simulated flows and reference flows. bmorph is designed to bias correct streamflow simulated with [mizuroute](https://mizuroute.readthedocs.io/en/latest/). We denote the simulated flows as the \"raw\" flows when they are unocorrected, and the flows that will be used to correct the raw flows as the reference flows. In our case the reference flows are estimated no-reservoir-no-irrigation (NRNI) flows taken from the [River Management Joint Operating Committee (RMJOC)](https://www.bpa.gov/p/Generation/Hydro/Documents/RMJOC-II_Part_II.PDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw flows\n",
    "watershed_raw = xr.open_dataset('yakima_workflow/input/yakima_raw_flows.nc')[['IRFroutedRunoff', 'dlayRunoff', 'reachID']].load()\n",
    "# Update some metadata\n",
    "watershed_raw['seg'] = watershed_raw.isel(time=0)['reachID'].astype(np.int32)\n",
    "\n",
    "# Reference flows\n",
    "watershed_ref = xr.open_dataset('yakima_workflow/input/nrni_reference_flows.nc').load().rename({'outlet':'site'})[['seg', 'seg_id', 'reference_flow']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert ``mizuroute`` formatting to ``bmorph`` formatting\n",
    "\n",
    "``mizuroute_utils`` is our utility script that will handle converting\n",
    "Mizuroute outputs to what we need for ``bmorph``. For more information\n",
    "on what ``mizuroute_utils`` does specifically and how to change its \n",
    "parameters, check out ``data.rst``.\n",
    "\n",
    "Here we pull out coordinate data from the ovearching watershed\n",
    "for the specific basin we want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_ref = watershed_ref.sel(site=[r for r in ref_sites])\n",
    "\n",
    "for site, seg in site_to_seg.items():\n",
    "    if site in basin_ref['site']:\n",
    "        basin_ref['seg'].loc[{'site': site}] = seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pass it off to ``mizuroute_to_blendmorph``, the primary utility \n",
    "function for automating ``bmorph`` pre-procesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_met_seg = mizutil.mizuroute_to_blendmorph(\n",
    "    basin_topo, watershed_raw.copy(), basin_ref, watershed_met, \n",
    "    fill_method='r2').ffill(dim='seg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply ``bmorph`` bias correction\n",
    "\n",
    "We are almost to actually bias correcting! First we need to specify some parameters \n",
    "for correction. Returning to these parameters can help fine tune your bias \n",
    "corrections to the basin you are analyzing.\n",
    "\n",
    "In this notebook, all four variations of ``bmorph`` are demonstrated: \n",
    "IBC_U, IBC_C, SCBC_U, and SCBC_C, as described in ``bias_correction.rst``.\n",
    "\n",
    "The ``train_window`` is what we will use to train the bias correction\n",
    "model. This is the time range that is representative of the\n",
    "basin's expected behavior that ``bmorph`` should mirror.\n",
    "\n",
    "The ``bmorph_window`` is when ``bmorph`` should be applied to the series for\n",
    "bias correction.\n",
    "\n",
    "Lastly the ``reference_window`` is when the reference flows should be used to \n",
    "smooth the bias corrected flows. This is recommended to be set as equivalent to the\n",
    "``train_window``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = pd.date_range('1981-01-01', '1990-12-30')[[0, -1]]\n",
    "bmorph_window = pd.date_range('1991-01-01', '2005-12-30')[[0, -1]]\n",
    "reference_window = train_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``interval`` is the length of ``bmorph``'s application intervals, \n",
    "typically a factor of years to preserve hydrologic \n",
    "relationships. Note that for ``pandas.DateOffset``, 'year' and 'years' \n",
    "are different and an 's' should always be included here for ``bmorph``\n",
    "to run properly, even for a single year.\n",
    "\n",
    "``overlap`` describes how many days the bias correction cumulative distribtuion function\n",
    "windows should overlap in total with each other. ``overlap`` is evenly distributed before\n",
    "and after this window. This is used to reduce discontinuities between application periods.\n",
    "\n",
    "``condition_var`` names the variable to use in conditioning, such as maximum\n",
    "temperature (tmax), seasonal precipitation (seasonal_precip), or daily\n",
    "minimum temperature (tmin). At this time, only one conditioning\n",
    "meteorological variable can be used per ``bmorph`` execution. In this example,\n",
    "``tmax`` and ``seasonal_precip`` have been commented out to select ``tmin`` as\n",
    "the conditioning variable. If you wish to change this, be sure to either change\n",
    "which variables are commented out or change the value of ``condition_var`` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = pd.DateOffset(years=1)\n",
    "overlap = 90\n",
    "\n",
    "# Select from the various available meteorologic fields for conditioning\n",
    "#condition_var = 'tmax'\n",
    "#condition_var = 'seasonal_precip'\n",
    "condition_var = 'tmin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we name some configuration parameters for ``bmorph``'s conditional and univariate\n",
    "bias correction metods, respectively. If you have been following along with the\n",
    "rest of the naming conventions in this section so far, then there is\n",
    "nothing you need to change here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditonal_config = {\n",
    "    'data_path':  './yakima_workflow',\n",
    "    'output_prefix': \"yakima\",\n",
    "    'train_window': train_window,\n",
    "    'bmorph_window': bmorph_window,\n",
    "    'reference_window': reference_window,\n",
    "    'bmorph_interval': interval,\n",
    "    'bmorph_overlap': overlap,\n",
    "    'condition_var': condition_var\n",
    "}\n",
    "\n",
    "univariate_config = {\n",
    "    'data_path':  './yakima_workflow',\n",
    "    'output_prefix': \"yakima\",\n",
    "    'train_window': train_window,\n",
    "    'bmorph_window': bmorph_window,\n",
    "    'reference_window': reference_window,\n",
    "    'bmorph_interval': interval,\n",
    "    'bmorph_overlap': overlap,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You made it! Now we can actually bias correction with ``bmorph``! Depending\n",
    "on the size of your data and use of parallelism or not, the following cells\n",
    "will likely take the longest to run, so make certain everything else looks\n",
    "good to you before running it.\n",
    "\n",
    "First off we run the Independent Bias Corrections, which is completely contained\n",
    "in the cell below. If you are interested in ``bmorph``'s spatial consitency and conditioing\n",
    "bias corrections, this cell is not it. However, it can be useful to run at least once\n",
    "so you have a baseline method to compare to as you fine tune variables.\n",
    "\n",
    "Here we run through each of the gauge sites and correct them \n",
    "individually. Since independent bias correction can only be performed\n",
    "at locations with reference data, corrections are only performed at\n",
    "the gauge sites here. If you have not changed any naming conventions\n",
    "so far, then there is nothing that you need to alter here, it has all already\n",
    "been extracted above for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_u_flows = {}\n",
    "ibc_u_mults = {}\n",
    "ibc_c_flows = {}\n",
    "ibc_c_mults = {}\n",
    "\n",
    "raw_flows = {}\n",
    "ref_flows = {}\n",
    "\n",
    "for site, seg in tqdm(site_to_seg.items()):\n",
    "    raw_ts = basin_met_seg.sel(seg=seg)['IRFroutedRunoff'].to_series()\n",
    "    train_ts = basin_met_seg.sel(seg=seg)['IRFroutedRunoff'].to_series()\n",
    "    obs_ts = basin_met_seg.sel(seg=seg)['up_ref_flow'].to_series()\n",
    "    cond_var = basin_met_seg.sel(seg=seg)[f'up_{condition_var}'].to_series()\n",
    "    ref_flows[site] = obs_ts\n",
    "    raw_flows[site] = raw_ts\n",
    "\n",
    "    ## IBC_U (Independent Bias Correction: Univariate)\n",
    "    ibc_u_flows[site], ibc_u_mults[site] = bmorph.workflows.apply_interval_bmorph(\n",
    "        raw_ts, train_ts, obs_ts, train_window, bmorph_window, reference_window, interval, overlap)\n",
    "\n",
    "    ## IBC_C (Independent Bias Correction: Conditioned)\n",
    "    ibc_c_flows[site], ibc_c_mults[site] = bmorph.workflows.apply_interval_bmorph(\n",
    "        raw_ts, train_ts, obs_ts, train_window, bmorph_window, reference_window, interval, overlap,\n",
    "        raw_y=cond_var, train_y=cond_var, obs_y=cond_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you specify where ``mizuroute`` is installed on your system\n",
    "and set up some variables to store total flows.\n",
    "\n",
    "``output_prefix`` will be used to write and load files according to the\n",
    "basin's name, make certain to update this with the actual name of\n",
    "the basin you are analyzing so you can track where different files\n",
    "are writen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mizuroute_exe = f'{envdir}/route_runoff.exe' # mizuroute designation\n",
    "\n",
    "\n",
    "unconditioned_seg_totals = {}\n",
    "conditioned_seg_totals = {}\n",
    "unconditioned_site_totals = {}\n",
    "conditioned_site_totals = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use ``run_parallel_scbc`` to do the rest! This may take a while ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconditioned_seg_totals = bmorph.workflows.run_parallel_scbc(basin_met_seg, client, mizuroute_exe, univariate_config)\n",
    "conditioned_seg_totals = bmorph.workflows.run_parallel_scbc(basin_met_seg, client, mizuroute_exe, conditonal_config)\n",
    "# Here we select out our rerouted gauge site modeled flows.\n",
    "for site, seg in tqdm(site_to_seg.items()):\n",
    "    unconditioned_site_totals[site] = unconditioned_seg_totals['IRFroutedRunoff'].sel(seg=seg).to_series()\n",
    "    conditioned_site_totals[site] = conditioned_seg_totals['IRFroutedRunoff'].sel(seg=seg).to_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we combine all the data into a singular xarray.Dataset, putting a nice little bow\n",
    "on your basin's analysis. If you did not run all parts of bmoprh, make certain to comment\n",
    "out those lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scbc_c = bmorph.workflows.bmorph_to_dataarray(conditioned_site_totals, 'scbc_c')\n",
    "basin_analysis = xr.Dataset(coords={'site': list(site_to_seg.keys()), 'time': scbc_c['time']})\n",
    "basin_analysis['scbc_c'] = scbc_c\n",
    "basin_analysis['scbc_u'] = bmorph.workflows.bmorph_to_dataarray(unconditioned_site_totals, 'scbc_u')\n",
    "basin_analysis['ibc_u'] = bmorph.workflows.bmorph_to_dataarray(ibc_u_flows, 'ibc_u')\n",
    "basin_analysis['ibc_c'] = bmorph.workflows.bmorph_to_dataarray(ibc_c_flows, 'ibc_c')\n",
    "basin_analysis['raw'] = bmorph.workflows.bmorph_to_dataarray(raw_flows, 'raw')\n",
    "basin_analysis['ref'] = bmorph.workflows.bmorph_to_dataarray(ref_flows, 'ref')\n",
    "basin_analysis.to_netcdf(f'./yakima_workflow/output/{univariate_config[\"output_prefix\"]}_data_processed.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's take a look at our results\n",
    "\n",
    "If you look closely, the following plots are the same ones included in [Plotting](evaluation.rst/Plotting)! Because the plotting functions expect the variable `seg`, we will need to conflate `site` and `seg` for them to properly run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmorph.evaluation import plotting\n",
    "\n",
    "yakima_ds = xr.open_dataset(f'yakima_workflow/output/{univariate_config[\"output_prefix\"]}_data_processed.nc')\n",
    "yakima_ds = yakima_ds.rename({'site':'seg'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a few sites and colors to plot for consistency. To simplify our plots, we will only focus on `scbc_c` in the dataset we just created. The methods do allow for multiple methods to be compared at once however, so we will still need to store the singular `scbc_c` in a list.\n",
    "\n",
    "Feel free to mess around with the parameters of any of these plots. You can plot more sites if desired, or more methods, just make certain arguments properly line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_sites = ['KIOW','YUMW','BUM']\n",
    "select_sites_2 = ['KIOW','YUMW','BUM','KEE']\n",
    "bcs = ['scbc_c', 'scbc_u', 'ibc_c', 'ibc_u']\n",
    "colors = ['grey', 'black', 'red', 'orange', 'purple', 'blue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.compare_correction_scatter(\n",
    "    flow_dataset= yakima_ds, \n",
    "    plot_sites = select_sites,\n",
    "    raw_var = 'raw', \n",
    "    ref_var = 'ref', \n",
    "    bc_vars = bcs, \n",
    "    bc_names = [bc.upper() for bc in bcs],\n",
    "    plot_colors = list(colors[2:]),\n",
    "    pos_cone_guide = True,\n",
    "    neg_cone_guide = True,\n",
    "    symmetry = False,\n",
    "    title = '',\n",
    "    fontsize_legend = 120,\n",
    "    alpha = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_reduced_flows(\n",
    "    flow_dataset= yakima_ds, \n",
    "    plot_sites = select_sites_2, \n",
    "    interval = 'month',\n",
    "    raw_var = 'raw', raw_name = \"Uncorrected\",\n",
    "    ref_var = 'ref', ref_name = \"Reference\",\n",
    "    bc_vars = bcs, bc_names = [bc.upper() for bc in bcs],\n",
    "    plot_colors = colors\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilitiy Distribtutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.compare_mean_grouped_CPD(\n",
    "    flow_dataset= yakima_ds, \n",
    "    plot_sites = select_sites,\n",
    "    grouper_func = plotting.calc_water_year, \n",
    "    figsize = (60,40),\n",
    "    raw_var = 'raw', raw_name = 'Uncorrected',\n",
    "    ref_var = 'ref', ref_name = 'Reference',\n",
    "    bc_vars = bcs, bc_names = [bc.upper() for bc in bcs],\n",
    "    plot_colors = colors,\n",
    "    linestyles = 2 * ['-','-','-'],\n",
    "    markers = ['o', 'X', 'o', 'o', 'o', 'o'],\n",
    "    fontsize_legend = 90,\n",
    "    legend_bbox_to_anchor = (1.9,1.0)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box & Whisker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.kl_divergence_annual_compare(\n",
    "    flow_dataset= yakima_ds, \n",
    "    sites = select_sites,\n",
    "    fontsize_legend = 60, title = '',\n",
    "    raw_var = 'raw', raw_name = 'Uncorrected',\n",
    "    ref_var = 'ref', ref_name = 'Reference',\n",
    "    bc_vars = bcs, bc_names = [bc.upper() for bc in bcs],\n",
    "    plot_colors = ['grey','red', 'orange', 'purple', 'blue']\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmorph",
   "language": "python",
   "name": "bmorph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
